JobBatchName            = "LLM worker"

# Environment
universe                = docker
docker_image            = ghcr.io/bxia68/llm_kg_generator:dev037
docker_network_type     = host

# Artefact
Requirements            = (Target.HasCHTCStaging == true)
executable              = llm_start.sh
should_transfer_files   = YES
transfer_input_files    = llm_start.sh, llm.env
transfer_output_files   = ""

# Logging
stream_output           = true
output                  = condor_log/output.$(Cluster)-$(Process).txt
error                   = condor_log/error.$(Cluster)-$(Process).txt
log                     = condor_log/log.$(Cluster)-$(Process).txt

# Compute resources
request_cpus            = 1
request_memory          = 32GB
request_disk            = 32GB

# Extra GPU settings
request_gpus            = 1
require_gpus            = (Capability >= 8.0) && (GlobalMemoryMb >= 20000)
Requirements            = (Target.CUDADriverVersion >= 12.1)
+WantGPULab             = true
+GPUJobLength           = "short"

queue 2